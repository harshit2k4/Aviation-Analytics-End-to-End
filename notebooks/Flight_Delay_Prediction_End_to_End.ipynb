{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epidYvkJbTH2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path\n",
        "path = '/content/drive/MyDrive/dataset/flights.csv'\n",
        "\n",
        "# Load the dataset\n",
        "# Using low_memory=False because the dataset has mixed data types\n",
        "df = pd.read_csv(path, low_memory=False)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the binary target variable\n",
        "# 1 = Delayed (>15 mins), 0 = On Time (<=15 mins)\n",
        "df['Is_Delayed'] = (df['ARRIVAL_DELAY'] > 15).astype(int)\n",
        "\n",
        "# Check how many of each we have\n",
        "print(\"Target Variable Distribution:\")\n",
        "print(df['Is_Delayed'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "oFS-9DcDd85X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column\n",
        "missing_data = df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_data[missing_data > 0])\n",
        "\n",
        "# Check for duplicate rows\n",
        "print(f\"\\nNumber of duplicate rows: {df.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "Gg7s3s-fewZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are mostly empty (over 90% missing values)\n",
        "limit = len(df) * 0.9\n",
        "df_cleaned = df.dropna(thresh=limit, axis=1)\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "critical_cols = ['DEPARTURE_TIME', 'DEPARTURE_DELAY', 'ARRIVAL_DELAY']\n",
        "df_cleaned = df_cleaned.dropna(subset=critical_cols)\n",
        "\n",
        "# Check how much data is left?\n",
        "print(f\"Original rows: {len(df)}\")\n",
        "print(f\"Cleaned rows: {len(df_cleaned)}\")\n",
        "print(\"\\nRemaining missing values:\")\n",
        "print(df_cleaned.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "-9pXyNPYfQ_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select only numerical columns for correlation\n",
        "numerical_df = df_cleaned.select_dtypes(include=[np.number])\n",
        "\n",
        "# Calculate absolute correlation with the target 'Is_Delayed'\n",
        "correlations = numerical_df.corr()['Is_Delayed'].abs().sort_values(ascending=False)\n",
        "\n",
        "# Get the top 10 features (excluding the target itself)\n",
        "top_10_features = correlations.iloc[1:11]\n",
        "\n",
        "print(\"Top 10 Features Selected by Correlation\")\n",
        "print(top_10_features)\n",
        "\n",
        "# Visualization for EDA Report\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_10_features.values, y=top_10_features.index, palette='viridis')\n",
        "plt.title('Top 10 Features Correlated with Flight Delays')\n",
        "plt.xlabel('Absolute Correlation Coefficient')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6zIT2x3DguGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create a focused dataframe with only Top 10 features + the target\n",
        "selected_cols = list(top_10_features.index) + ['Is_Delayed']\n",
        "df_final = df_cleaned[selected_cols].copy()\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = df_final.drop('Is_Delayed', axis=1)\n",
        "y = df_final['Is_Delayed']\n",
        "\n",
        "# Standardize the data (Mean=0, Variance=1)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"Data successfully transformed and scaled.\")\n",
        "print(f\"Final shape for modeling: {X_scaled.shape}\")"
      ],
      "metadata": {
        "id": "TdH7rNRehUzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "# To save time and memory, sample 100,000 rows from our 5.7M rows\n",
        "# This keeps the project manageable for SVM and KNN\n",
        "df_sample = df_final.sample(n=100000, random_state=42)\n",
        "\n",
        "X_sample = df_sample.drop('Is_Delayed', axis=1)\n",
        "y_sample = df_sample['Is_Delayed']\n",
        "\n",
        "# Balance Report (Before SMOTE)\n",
        "print(f\"Distribution before SMOTE: {Counter(y_sample)}\")\n",
        "\n",
        "# Apply SMOTE to balance the 17% delayed flights with the 83% on-time flights\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_sample, y_sample)\n",
        "\n",
        "# Balance Report (After SMOTE)\n",
        "print(f\"Distribution after SMOTE: {Counter(y_resampled)}\")"
      ],
      "metadata": {
        "id": "0NZ_FxvBhoFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}